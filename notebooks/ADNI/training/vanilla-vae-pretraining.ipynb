{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 15 13:43:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A2000 12GB          Off |   00000000:01:00.0 Off |                  Off |\n",
      "| 30%   36C    P8             10W /   70W |     114MiB /  12282MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1901      G   /usr/libexec/Xorg                              94MiB |\n",
      "|    0   N/A  N/A      2037      G   /usr/bin/gnome-shell                           13MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../../lib/src/')\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "from lib.src.pythae.models import VAE\n",
    "from lib.scripts.utils import Encoder_ADNI, Decoder_ADNI, My_Dataset\n",
    "from lib.src.pythae.models.vae import VAEConfig\n",
    "from lib.src.pythae.trainers import BaseTrainerConfig\n",
    "from lib.src.pythae.pipelines.training import TrainingPipeline\n",
    "from lib.src.pythae.samplers.normal_sampling import NormalSampler\n",
    "from lib.src.pythae.samplers.manifold_sampler import RHVAESampler\n",
    "from lib.src.pythae.trainers.training_callbacks import WandbCallback\n",
    "from lib.src.pythae.models.nn import BaseEncoder, BaseDecoder\n",
    "from lib.src.pythae.models.base.base_utils import ModelOutput\n",
    "\n",
    "from geometric_perspective_on_vaes.sampling import build_metrics, hmc_sampling\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 8, 120])\n",
      "torch.Size([56800, 120])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_data = torch.load('data-models/adni/data/ADNI_train.pt') #(N, T, D)\n",
    "eval_data = torch.load('data-models/adni/data/ADNI_eval.pt')\n",
    "test_data = torch.load('data-models/adni/data/ADNI_test.pt')\n",
    "print(train_data.shape)\n",
    "\n",
    "train_seq_mask = torch.load('data-models/adni/data/ADNI_train_seq_mask.pt') #(N, T)\n",
    "eval_seq_mask = torch.load('data-models/adni/data/ADNI_eval_seq_mask.pt')\n",
    "test_seq_mask = torch.load('data-models/adni/data/ADNI_test_seq_mask.pt')\n",
    "\n",
    "\n",
    "#Take only non-NaN values\n",
    "train_data = train_data[train_seq_mask == 1]\n",
    "eval_data = eval_data[eval_seq_mask == 1]\n",
    "test_data = test_data[test_seq_mask == 1]\n",
    "print(train_data.shape)\n",
    "\n",
    "train_pix_mask = torch.ones_like(train_data, requires_grad=False).type(torch.bool)\n",
    "eval_pix_mask = torch.ones_like(eval_data, requires_grad=False).type(torch.bool)\n",
    "test_pix_mask = torch.ones_like(test_data, requires_grad=False).type(torch.bool)\n",
    "\n",
    "train_dataset = My_Dataset(train_data)\n",
    "eval_dataset = My_Dataset(eval_data)\n",
    "test_dataset = My_Dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 9\n",
    "input_dim = (1, 120)\n",
    "encoder = Encoder_ADNI(input_dim, latent_dim)\n",
    "decoder = Decoder_ADNI(input_dim, latent_dim)\n",
    "\n",
    "model_config = VAEConfig(input_dim=input_dim, latent_dim= latent_dim, uses_default_encoder= False, uses_default_decoder= False, reconstruction_loss= 'mse')\n",
    "vae = VAE(model_config=model_config, encoder=encoder, decoder=decoder)\n",
    "\n",
    "training_config = BaseTrainerConfig(output_dir='pre-trained_vae',\n",
    "num_epochs=50,\n",
    "learning_rate=5*1e-5,\n",
    "per_device_train_batch_size=32,\n",
    "per_device_eval_batch_size=64,\n",
    "train_dataloader_num_workers=2,\n",
    "eval_dataloader_num_workers=2,\n",
    "steps_saving=25,\n",
    "optimizer_cls=\"AdamW\",\n",
    "optimizer_params={\"weight_decay\": 0.05, \"betas\": (0.91, 0.995)},\n",
    "scheduler_cls=\"ReduceLROnPlateau\",\n",
    "scheduler_params={\"patience\": 3, \"factor\": 0.8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [] # the TrainingPipeline expects a list of callbacks\n",
    "wandb_cb = WandbCallback() # Build the callback \n",
    "# SetUp the callback \n",
    "wandb_cb.setup(\n",
    "    training_config=training_config, # pass the training config\n",
    "    model_config = model_config,\n",
    "    project_name=\"pre_training_VAE_latdim9_fulldataset\", # specify your wandb project # specify your wandb entity\n",
    ")\n",
    "callbacks.append(wandb_cb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = vae.to('cuda')\n",
    "pipeline = TrainingPipeline(\n",
    "    training_config=training_config,\n",
    "    model=vae\n",
    ")\n",
    "pipeline(\n",
    "    train_data=train_dataset,\n",
    "    eval_data=eval_dataset,\n",
    "    #callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
